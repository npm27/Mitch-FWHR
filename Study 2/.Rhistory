JOL3 = JOL3[ , -5]
RL3 = RL3[ , -5]
VC3 = VC3[ , -5]
Study3 = Study3[ , -5]
JOL4 = cast(JOL3, Username ~ Direction, mean)
RL4 = cast(RL3, Username ~ Direction, mean)
VC4 = cast(VC3, Username ~ Direction, mean)
Study4 = cast(Study3, Username ~ Direction, mean)
####Get Sds for cohen's d####
sd_jol = apply(JOL4, 2, sd)
sd_RL = apply(RL4, 2, sd)
sd_VC = apply(VC4, 2, sd)
sd_ST = apply(Study4, 2, sd)
sd_jol;sd_RL;sd_VC;sd_ST
#Get means
m_jol = apply(JOL4, 2, mean)
m_RL = apply(RL4, 2, mean)
m_VC = apply(VC4, 2, mean)
m_ST = apply(Study4, 2, mean)
#Get se's
se_jol = sd_jol / sqrt(nrow(JOL4))
se_RL = sd_RL / sqrt(nrow(RL4))
se_VC = sd_VC / sqrt(nrow(VC4))
se_ST = sd_ST / sqrt(nrow(Study4))
#Get CI's ##These are for the table
ci_jol = se_jol * 1.96
ci_RL = se_RL * 1.96
ci_VC = se_VC * 1.96
ci_ST = se_ST * 1.96
##Get Upper
u_jol = ci_jol + m_jol
u_RL = ci_RL + m_RL
u_VC = ci_VC + m_VC
u_ST = ci_ST + m_ST
##Get Lower
l_jol = m_jol - ci_jol
l_RL = m_RL - ci_RL
l_VC = m_VC - ci_VC
l_ST = m_ST - ci_ST
####Now run t-tests for interaction####
###Forward
##Jol vs RL
temp = t.test(JOL4$F, RL4$F, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-Sig
##JOL vs Study
temp = t.test(JOL4$F, Study4$F, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##Jol vs VC
temp = t.test(JOL4$F, VC4$F, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##RL vs Study
temp = t.test(RL4$F, Study4$F, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##RL vs VC
temp = t.test(RL4$F, VC4$F, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##VC vs Study
temp = t.test(VC4$F, Study4$F, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
###Backward
##Jol vs RL
temp = t.test(JOL4$B, RL4$B, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-Sig
##JOL vs Study
temp = t.test(JOL4$B, Study4$B, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##Jol vs VC
temp = t.test(JOL4$B, VC4$B, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##RL vs Study
temp = t.test(RL4$B, Study4$B, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##RL vs VC
temp = t.test(RL4$B, VC4$B, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##VC vs Study
temp = t.test(VC4$B, Study4$B, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-Sig
###Symmetrical
##Jol vs RL
temp = t.test(JOL4$S, RL4$S, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-Sig
##JOL vs Study
temp = t.test(JOL4$S, Study4$S, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##Jol vs VC
temp = t.test(JOL4$S, VC4$S, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##RL vs Study
temp = t.test(RL4$S, Study4$S, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##RL vs VC
temp = t.test(RL4$S, VC4$S, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##VC vs Study
temp = t.test(VC4$S, Study4$S, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
###unrelated
##Jol vs RL
temp = t.test(JOL4$U, RL4$U, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #SIG!
##JOL vs Study
temp = t.test(JOL4$U, Study4$U, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #NON-Sig
##Jol vs VC
temp = t.test(JOL4$U, VC4$U, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #NON-Sig
##RL vs Study
temp = t.test(RL4$U, Study4$U, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##RL vs VC
temp = t.test(RL4$U, VC4$U, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
##VC vs Study
temp = t.test(VC4$U, Study4$U, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #NON-Sig
####Reactivity pbic stuff####
##Direction
##Study group
pbic = rbind(VC4, Study4)
encoding.s = Encoding[ , c(1, 4)]
encoding.v = Encoding[ , c(1, 5)]
encoding.j = Encoding[ , c(1, 2)]
encoding.r = Encoding[ , c(1, 3)]
colnames(encoding.s)[2] = "Score"
colnames(encoding.v)[2] = "Score"
colnames(encoding.r)[2] = "Score"
colnames(encoding.j)[2] = "Score"
encoding.s$task = rep("study")
encoding.v$task = rep("vowel")
encoding.r$task = rep("rl")
encoding.j$task = rep("jol")
dat1 = rbind(encoding.j, encoding.r)
dat2 = rbind(encoding.v, encoding.s)
dat1 = na.omit(dat1)
dat2 = na.omit(dat2)
modela = ezANOVA(dat2,
dv = Score,
wid = Username,
between = task,
type = 3,
detailed = T)
modela
##Interaction
JOL4$task = rep("jol")
RL4$task = rep("RL")
VC4$task = rep("vc")
Study4$task = rep("study")
pbic = rbind(JOL4, RL4)
pbic2 = rbind(Study4, VC4)
pbic3 = rbind(VC4, JOL4)
colnames(pbic)[3] = "f"
modelb = ezANOVA(pbic,
dv = f,
wid = Username,
between = task,
type = 3,
detailed = T)
modelb
#check sds
tapply(JOL$Response.JOL, JOL$Direction, sd, na.rm = T)
##RL vs VC
temp = t.test(RL4$U, VC4$U, paired = F, p.adjust.methods = "bonferroni")
temp
##RL vs Study
temp = t.test(RL4$S, Study4$S, paired = F, p.adjust.methods = "bonferroni")
temp
##Jol vs VC
temp = t.test(JOL4$S, VC4$S, paired = F, p.adjust.methods = "bonferroni")
temp
##RL vs VC
temp = t.test(RL4$S, VC4$S, paired = F, p.adjust.methods = "bonferroni")
temp
##VC vs Study
temp = t.test(VC4$S, Study4$S, paired = F, p.adjust.methods = "bonferroni")
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Sig
p.adjust(temp$p.value, method = "BY", n = 3)
p.adjust(temp$p.value, method = "bonferonni", n = 3)
p.adjust(temp$p.value, method = "bonferroni", n = 3)
p.adjust(temp$p.value, method = "holm", n = 3)
p.adjust(temp$p.value, method = "hochberg", n = 3)
p.adjust(temp$p.value, method = "hommel", n = 3)
p.adjust(temp$p.value, method = "bonferroni", n = 3)
setwd("~/GitHub/Mitch-FWHR/Study 1")
#Study1
#2 x 2 repeated design
####Set up####
##Load libraries
library(memisc) #read in .sav
library(reshape) #data wrangling
library(lme4) #Mixed effects models
library(nlme) #more mixed effects models
library(ez) #anovas
library(car) #get p-values
library(effects) #maybe use this for interactions?
library(ggplot2) #plot the things!
library(emmeans)
##turn of scientific notation
options(scipen = 999)
##Read in the dataset
dat = as.data.set(spss.system.file("Study1.sav"))
dat = as.data.frame(dat)
##Check the data
summary(dat)
length(unique(dat$id))
#fix column names
colnames(dat)[2] = "High1N"
colnames(dat)[3] = "High1P"
#which ones are female?
table(dat$Sex) #2's
#let's factor sex
dat$Sex = factor(dat$Sex,
levels = c(1, 2),
labels = c("Male", "Female"))
##Get the data in long format
#going to drop the mean columns
dat.long = melt(dat[ , -c(45:48)],
id.vars = c("id", "Sex", "Age", "Race"))
colnames(dat.long)[5:6] = c("Type", "Score")
##now split out "type" column to get high/low and N/P
#fwhr
dat.long$fwhr = dat.long$Type
dat.long$fwhr = substr(dat.long$fwhr, 0, 1)
#parenting
dat.long$Type = sub('.*(?=.{2}$)', '', dat.long$Type, perl=T)
dat.long$Type = substr(dat.long$Type, 2, 2)
colnames(dat.long)[5] = "Parenting"
#make score numeric
dat.long$Score = as.numeric(dat.long$Score)
####Analyses####
##first try to reproduce the means
tapply(dat.long$Score, list(dat.long$Parenting, dat.long$fwhr), mean, na.rm = T)
#Remove the one NA
dat.long = na.omit(dat.long)
##Now the anova
ezANOVA(dat.long,
wid = id,
between = Sex,
within = .(Parenting, fwhr),
dv = Score,
type = 3,
detailed = T)
####model time!####
##Try LME model first
model1 = lme(Score ~ Sex * Parenting * fwhr,
data = dat.long,
method = "ML",
na.action = "na.omit",
random = ~1|id)
summary(model1)
Anova(model1) #big A gets you p-values
#Try lmer
model2 = lmer(Score ~ Sex * Parenting * fwhr + (1|id),
data = dat.long,
REML = FALSE)
summary(model2)
Anova(model2)
##Okay, I like the lmer model better syntax wise, but both return the same output. I will take that as a good sign.
#first, fit an intercept only model
model2.int = lmer(Score ~  + (1|id),
data = dat.long,
REML = FALSE)
summary(model2.int)
#now add the effects
#add the between first
model2.between = lmer(Score ~ Sex + (1|id),
data = dat.long,
REML = FALSE)
summary(model2.between)
##compare models (full model should have a better fit)
anova(model2.int, model2.between, model2) #notice the little a!
#AIC and BIC both decrease for our final model (model2) meaning that it provides the best fit to our data
####Interaction####
e = allEffects(model2)
e
plot(e) ##Okay, this gets us the 3-way, but what about the 2-way?
#also, 3-way not sig, but something is going on between fwhr and parenting as indicated by the 2-way
##break down the 2-way between parenting and fwhr
ef1 = effect(term = "Parenting * fwhr",  mod = model2)
plot(ef1)
##Try another way of visualizing
plot(ef1, multiline = TRUE, confint = TRUE, ci.style = "bars",
main = "Parenting perceptions as a function of Parenting role and fwhr",
xlab = "Parenting",
ylab = "Score")
##and let's try one more
emmip(model2, fhwr ~ Parenting)
Anova(model2)
summary(model2)
summary(model2)
Anova(model2)
summary(model2)
##compare models (full model should have a better fit)
anova(model2.int, model2.between, model2) #notice the little a!
##compare models (full model should have a better fit)
anova(model2.between, model2) #notice the little a!
##compare models (full model should have a better fit)
anova(model2.int, model2.between, model2) #notice the little a!
model2.no_rand = lmer(Score ~ id,
data = dat.long,
REML = F)
model2.no_rand = lm(Score ~ id,
data = dat.long,
REML = F)
model2.no_rand = lm(Score ~ id,
data = dat.long)
model2.no_rand = lm(Score ~  + id,
data = dat.long)
model2.no_rand = lm(Score ~  ,
data = dat.long)
model2.no_rand = lm(Score ~  ,
data = dat.long)
model2.no_rand = lm(Score ~  1,
data = dat.long)
##compare models (full model should have a better fit)
anova(model2.no_rand, model2.int, model2.between, model2) #notice the little a!
model2.no_rand = lm(Score ~ Sex * Parenting * fwhr,
data = dat.long)
##compare models (full model should have a better fit)
anova(model2.int, model2.between, model2.no_rand, model2) #notice the little a!
##compare models (full model should have a better fit)
anova(model2.no_rand, model2) #notice the little a!
##compare models (full model should have a better fit)
anova(model2.int, model2.between, model2.no_rand) #notice the little a!
##compare models (full model should have a better fit)
anova(model2.int, model2.no_rand) #notice the little a!
lmtest::lrtest(model2.int, model2.between)
lmtest::lrtest(model2.int, model2.between, model2)
##compare models (full model should have a better fit)
anova(model2.int, model2.between, model2) #notice the little a!
lmtest::lrtest(model2.int, model2.between, model2, model2.no_rand)
lmtest::lrtest(model2, model2.no_rand)
lmtest::lrtest(model2.no_rand, model2.no_rand)
lmtest::lrtest(model2.no_rand, model2)
lmtest::lrtest(model2.int, model2.between, model2.no_rand, model2)
lmtest::lrtest(model2.int, model2.between, model2)
lmtest::lrtest(model2.between, model2)
lmtest::lrtest(model2.int, model2)
bayestestR::bayesfactor_models(model2, denominator = model2.int)
options(scipen = 999)
bayestestR::bayesfactor_models(model2, denominator = model2.int)
options(scipen = 999)
bayestestR::bayesfactor_models(model2, denominator = model2.int)
bayestestR::bayesfactor_models(model2, denominator = model2.between)
bayestestR::bayesfactor_models(model2, denominator = model2.int)
Anova(model2)
Anova(model2, type = "III")
summary(model2)
setwd("~/GitHub/Mitch-FWHR/Study 2")
####Set up####
##load libraries
library(memisc)
library(reshape)
library(ez)
library(lme4)
library(car)
library(effects) #maybe use this for interactions?
library(ggplot2) #plot the things!
library(emmeans)
##turn of scientific notation
options(scipen = 999)
##load data
dat = as.data.set(spss.system.file("Study 2.sav"))
dat = as.data.frame(dat)
##see what we're working with
summary(dat)
length(unique(dat$id))
####Get the data in the right format####
##Get the data in long format
#going to drop the mean columns
dat.long = melt(dat[ , -c(45:52)],
id.vars = c("id", "Sex", "Age", "Race"))
colnames(dat.long)[5:6] = c("Type", "Score")
#now split out "type" column to get high/low, N/P, I/U
#FWHR
dat.long$fwhr = dat.long$Type
dat.long$fwhr = substr(dat.long$fwhr, 0, 1)
#PARENTING
dat.long$Parenting = dat.long$Type
dat.long$Parenting = sub('.*(?=.{2}$)', '', dat.long$Parenting, perl = T)
dat.long$Parenting = substr(dat.long$Parenting, 1, 1)
#Presentation
dat.long$Type = sub('.*(?=.{2}$)', '', dat.long$Type, perl = T)
dat.long$Type = substr(dat.long$Type, 2, 2)
colnames(dat.long)[5] = "Presentation"
#make score numeric
dat.long$Score = as.numeric(dat.long$Score)
##check out the final dataset
summary(dat.long)
####Can I recreate the ANOVA?####
ezANOVA(dat.long,
wid = id,
between = Sex,
within = .(Parenting, fwhr, Presentation),
dv = Score,
type = 3,
detailed = T)
####Mixed effects time!####
##based on S1, going to use lmer models
#go ahead and start with final model
model.final = lmer(Score ~ Sex * Parenting * fwhr * Presentation + (1|id),
data = dat.long,
REML = FALSE)
summary(model.final)
Anova(model.final)
#Intercept only
model.int = lmer(Score ~  + (1|id),
data = dat.long,
REML = FALSE)
summary(model.int)
#between only
model.between = lmer(Score ~ Sex + (1|id),
data = dat.long,
REML = FALSE)
summary(model.between)
##compare models (full model should have a better fit)
anova(model.int, model.between, model.final)
####Breakdown the interaction(s)####
##break down the 2-way between parenting and fwhr
ef1 = effect(term = "Parenting * fwhr",  mod = model.final)
plot(ef1)
##Try another way of visualizing
plot(ef1, multiline = TRUE, confint = TRUE, ci.style = "bars",
main = "Parenting perceptions as a function of Parenting Role and fwhr",
xlab = "Parenting",
ylab = "Score")
##compare models (full model should have a better fit)
anova(model.int, model.final)
anova(model.between, model.final)
##Get BF
bayestestR::bayesfactor_models(model.final, denominator = model.int)
bayestestR::bayesfactor_models(model.final, denominator = model.between)
summary(model.final)
Anova(model.final)
Anova(model.final, type = "III")
summary(model.final)
Anova(model.final, type = "III")
